{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNVNGdnHx6oLTp1DAlgxTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sompote/SPT_Bangkok_SAND/blob/main/SPT_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpWexyhPOIud",
        "outputId": "19c5dd9a-3fe9-4236-c9e7-7b34f0df7907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0055\n",
            "mean absolute percentage error: 9.249404784399546\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0078\n",
            "mean absolute percentage error: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-0213273b29b0>:30: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return np.mean(np.abs((actual - pred) / actual)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051\n",
            "mean absolute percentage error: 9.640417978523065\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038\n",
            "mean absolute percentage error: 19.20486832264044\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0011\n",
            "mean absolute percentage error: 2.978753160229374\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.5044e-04\n",
            "mean absolute percentage error: 11.241484053850087\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.3129e-04\n",
            "mean absolute percentage error: 13.614616582149255\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.6492e-05\n",
            "mean absolute percentage error: 1.6070000715448316\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_excel('SPT.xlsx')\n",
        "data=np.array(df)\n",
        "X=data[:,0:2]\n",
        "y=data[:,2]\n",
        "y=np.reshape(y,(X.shape[0],1))\n",
        "\n",
        "# Load and preprocess data\n",
        "from sklearn.model_selection import KFold\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "sc = MinMaxScaler()\n",
        "sc_y=MinMaxScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "y_train=sc_y.fit_transform(y_train)\n",
        "y_test=sc_y.transform(y_test)\n",
        "def mape(actual, pred):\n",
        "  return np.mean(np.abs((actual - pred) / actual)) * 100\n",
        "\n",
        "# Define neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "k = 8 # number of folds kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "mse_list = []\n",
        "mape_list = []\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "  X_train_fold, X_test_fold = X_train[train_index],X_train[test_index]\n",
        "  y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "  model.fit(X_train_fold, y_train_fold, batch_size=5, epochs=500,verbose=0)\n",
        "  y_pred_fold = model.predict(X_test_fold)\n",
        "  mse_fold = model.evaluate(X_test_fold, y_test_fold)\n",
        "  mape_fold = mape(y_test_fold, y_pred_fold)\n",
        "  mse_list.append(mse_fold)\n",
        "  mape_list.append(mape_fold)\n",
        "  print('mean absolute percentage error:', mape_fold)\n",
        "mse_avg = np.mean(mse_list)\n",
        "mape_avg = np.mean(mape_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot and save your model\n",
        "import tensorflow as tf\n",
        "img_file = 'model.png'\n",
        "tf.keras.utils.plot_model(model, to_file=img_file, show_shapes=True, show_layer_names=True)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVfcl3TuOeuc",
        "outputId": "2a354e5c-5f68-4df4-8c3d-d5944b405bc8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 100)               300       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 255       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,611\n",
            "Trainable params: 5,611\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model.save('model.h5')\n",
        "pickle.dump(sc, open('scaler.pkl', 'wb'))\n",
        "pickle.dump(sc_y, open('scaler_y.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "BI0wHx1aOp-8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reEKrBvaTXCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}